{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "import matplotlib as mlp\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error,adjusted_mutual_info_score,adjusted_rand_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file1='train3.csv'\n",
    "dataframe=pd.read_csv(file1)\n",
    "dataframe=dataframe.dropna(axis=0)\n",
    "dataframe=dataframe.drop(['area','price'],1)\n",
    "\n",
    "#dataframe1=dataframe[['lat', 'lon', 'bhk','city', 'type', 'rate','source','price']]\n",
    "#dataframe2=dataframe\n",
    "\n",
    "df=dataframe\n",
    "print(df.columns,df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple type of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter option\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter option\")\n",
    "option=int(input())\n",
    "data=pd.DataFrame()\n",
    "\n",
    "#all\n",
    "df=df\n",
    "source=df['source'].unique()\n",
    "print(df['source'].unique())\n",
    "\n",
    "if option==0:\n",
    "  df0=df\n",
    "  df0=df0.drop(['source'],1)\n",
    "  data=df0\n",
    "\n",
    "#All data 1 source\n",
    "if option==1:\n",
    "   print(\"Enter Source number\")\n",
    "   i1=int(input())\n",
    "   df1=df[(df['source'] == source[i1])]\n",
    "   df1=df1.drop(['source'],1)\n",
    "   data=df1\n",
    "\n",
    "#Mix All data\n",
    "if option==2:\n",
    "   print(\"Enter Source number 1 & 2\")\n",
    "   i=int(input())\n",
    "   j=int(input())\n",
    "   df2=df[(df['source'] == source[i])]\n",
    "   df2=pd.concat([ df1, df[(df['source'] == source[j])]])\n",
    "   df2=df2.drop(['price','source'],1)\n",
    "   data=df2\n",
    "#Mix3rd quartile\n",
    "if option==4:\n",
    "   print(\"Enter Source number 1 & 2\")      \n",
    "   i=int(input())\n",
    "   j=int(input())\n",
    "   df3=df[(df['source'] == source[i]) & (df['rate']<df['rate'].describe()[6])]\n",
    "   df3=pd.concat([ df3, df[(df['source'] == source[j]) & (df['rate']<df['rate'].describe()[6])]])\n",
    "   df3=df3.drop(['price','source'],1)\n",
    "   data=df3\n",
    "\n",
    "#mix 30000\n",
    "if option==5:\n",
    "   print(\"Enter Source number 1 & 2\")\n",
    "   i=int(input())\n",
    "   j=int(input())\n",
    "   df4=df[((df['source'] == source[i])|(df['source'] == source[j]))&\n",
    "       (df['rate']<30000)]\n",
    "   df4=df4.drop(['price','source'],1)\n",
    "   data=df4\n",
    "\n",
    "#15000 mix\n",
    "if option==6:\n",
    "   print(\"Enter Source number 1 & 2\")\n",
    "   i=int(input())\n",
    "   j=int(input())\n",
    "   df5=df[((df['source'] == source[i])|(df['source'] == source[j]))&\n",
    "       (df['rate']<15000)]\n",
    "   df5=df5.drop(['price','source'],1)\n",
    "   data=df5\n",
    "    \n",
    "if option==7:\n",
    "   print(\"Enter Source number\")\n",
    "   i1=int(input())\n",
    "   df1=df[(df['source'] == source[i1])]\n",
    "   df1=df1.drop(['source'],1)\n",
    "   data=df1[:20000]\n",
    "\n",
    "\n",
    "#data=Normalize(data)\n",
    "#Plot(data)\n",
    "#data=Outlier(daat)\n",
    "#data=TransformLog(data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot with outlier\n",
    "#plot all feature vs target\n",
    "\n",
    "\n",
    "def PlotAll():\n",
    "        import matplotlib.pyplot as plt\n",
    "        df=NullEncoding(data)\n",
    "        X=df.copy()\n",
    "        del X['rate']\n",
    "        for i in X.columns:\n",
    "\n",
    "          plt.scatter(X[i], df['rate'], edgecolor='black', s=20)\n",
    "          plt.xlabel(i, fontsize=14)\n",
    "          plt.ylabel(\"rate\", fontsize=14)\n",
    "          plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names,get_fscore,get_score=Start(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Start(df):\n",
    "    \n",
    "    df=NullEncoding(df)\n",
    "    \n",
    "    df=FeatureSelection(df)\n",
    "    \n",
    "    print(df.columns)\n",
    "    \n",
    "    a,b,c,d=Split(df)\n",
    "    \n",
    "    dtrain,params,num_round,feature_names,get_fscore,get_score=Model1(a,b,c,d)\n",
    "    \n",
    "    return feature_names,get_fscore,get_score\n",
    "    \n",
    "    \n",
    " \n",
    "    #param=Tuning(dtrain,params,num_round)\n",
    "    # Model2( a, b, c, d,param[0],param[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransformLog(df1):\n",
    "    df1['rate']=np.log(df1['rate'])\n",
    "    for i in df1.columns:\n",
    "     if df1[df1[i]==0].shape[0]==0:\n",
    "       if np.corrcoef(df1['rate'],np.log(df1[i]))[0][1]> np.corrcoef(df1['rate'],df1[i])[0][1]:\n",
    "          print(i)\n",
    "          df1[i]=np.log(df1[i])\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(df1):\n",
    "  index0=df1[(df1['rate']<df1['rate'].describe()[5])].index\n",
    "  index1=df1[(df1['rate']>df1['rate'].describe()[5])].index\n",
    "  from random import randrange\n",
    "  random=[i  for i  in index0  if i%2==0]\n",
    "  index2=sorted(tuple(set(random).union(set(index1))))\n",
    "  index=[i for i in index2 if i in df1.index]\n",
    "  df1=df1.ix[index,:]\n",
    "  return df1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot target variable /Stats of target #distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot(df1)   :\n",
    "   Y=df1['rate']\n",
    "   # Import library and dataset\n",
    "   import seaborn as sns\n",
    "   # Control the number of bins\n",
    "   sns.distplot(Y, bins=20)\n",
    "   #print(df1['rate'].describe())\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Outlier(df1):\n",
    "    from sklearn.covariance import EllipticEnvelope\n",
    "    i1=EllipticEnvelope().fit(df1).predict(df1)\n",
    "    from sklearn.neighbors import LocalOutlierFactor\n",
    "    i2=LocalOutlierFactor().fit_predict(df1)\n",
    "    \n",
    "    \n",
    "    d=dict(zip(df1.index,i1))\n",
    "    index1=[i for i in d.keys() if d[i]==1 ]\n",
    "    d=dict(zip(df1.index,i2))\n",
    "    index2=[i for i in d.keys() if d[i]==1 ]\n",
    "   \n",
    "    \n",
    "    df1=df1.ix[sorted(list(set(index1).union(set(index2))))]\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. NAN/NULL/Missing                   2.  Numerical data/Categorical data/Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NullEncoding(df2):\n",
    "      numCols=[]\n",
    "      for i in df2.columns:\n",
    "        if df2[i].dtypes=='int64' or df2[i].dtypes=='float64':\n",
    "            \n",
    "               #if np.corrcoef(df2[i],target)[0][1]>.1:\n",
    "               numCols.append(i)\n",
    "              \n",
    "      \n",
    "      #categorical\n",
    "      StringCol=[]\n",
    "      for i in df2.columns:\n",
    "          if df2[i].dtypes!='int64' and df2[i].dtypes!='float64':\n",
    "              df2[i]=df2[i].apply(str)\n",
    "              le=preprocessing.LabelEncoder().fit(df2[i])\n",
    "              df2[i] =le.transform(df2[i])\n",
    "              pd.to_numeric(df2[i]).astype(np.float)\n",
    "              StringCol.append(i)\n",
    "      final=StringCol+numCols\n",
    "    \n",
    "      df2=df2.dropna(axis=0)\n",
    "      return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureSelection(df):\n",
    "    df1=df.copy()\n",
    "    a,b,c,d=Split(df1)\n",
    "    feature_names,get_fscore=Model3(a,b,c,d)\n",
    "    import operator\n",
    "    sorted1 = sorted(get_fscore.items(), key=operator.itemgetter(1))\n",
    "    col=sorted1\n",
    "   \n",
    "    \n",
    "    v=[i[1] for i in col]\n",
    "    k1=[i[0] for i in col if i[1]>np.mean(v)]\n",
    "        \n",
    "    df2=df[k1].copy()\n",
    "    df2['rate']=df['rate']\n",
    "    return df2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureSelection(df):\n",
    "    df1=df.copy()\n",
    "    a,b,c,d=Split(df1)\n",
    "    feature_names,get_fscore=Model3(a,b,c,d)\n",
    "    import operator\n",
    "    sorted1 = sorted(get_fscore.items(), key=operator.itemgetter(1))\n",
    "    col=sorted1\n",
    "   \n",
    "    \n",
    "    v=[i[1] for i in col]\n",
    "    k1=[i[0] for i in col if i[1]>np.median(v)]\n",
    "        \n",
    "    df2=df[k1].copy()\n",
    "    df2['rate']=df['rate']\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=[range(1,100)]\n",
    "type(np.mean(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fscore.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mae:3337.54\ttest-mae:2914.27\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "[1]\ttrain-mae:2361.46\ttest-mae:2180.34\n",
      "[2]\ttrain-mae:1696.42\ttest-mae:1683.37\n",
      "[3]\ttrain-mae:1251.59\ttest-mae:1420.57\n",
      "[4]\ttrain-mae:919.232\ttest-mae:1219.8\n",
      "[5]\ttrain-mae:708.608\ttest-mae:1072.24\n",
      "[6]\ttrain-mae:561.589\ttest-mae:1027.19\n",
      "[7]\ttrain-mae:458.131\ttest-mae:998.233\n",
      "[8]\ttrain-mae:401.342\ttest-mae:949.288\n",
      "[9]\ttrain-mae:360.819\ttest-mae:978.833\n",
      "[10]\ttrain-mae:332.099\ttest-mae:966.707\n",
      "[11]\ttrain-mae:305.506\ttest-mae:967.763\n",
      "[12]\ttrain-mae:288.545\ttest-mae:977.112\n",
      "[13]\ttrain-mae:273.981\ttest-mae:962.045\n",
      "[14]\ttrain-mae:257.512\ttest-mae:970.988\n",
      "[15]\ttrain-mae:259.278\ttest-mae:984.23\n",
      "[16]\ttrain-mae:244.28\ttest-mae:1012.38\n",
      "[17]\ttrain-mae:225.694\ttest-mae:1024.77\n",
      "[18]\ttrain-mae:224.127\ttest-mae:1024.74\n",
      "Stopping. Best iteration:\n",
      "[8]\ttrain-mae:401.342\ttest-mae:949.288\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1480607d828>]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14806059f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1=df[:100].copy()\n",
    "df1=NullEncoding(df1)\n",
    "a,b,c,d=Split(df1)\n",
    "feature_names,get_fscore=Model3(a,b,c,d)\n",
    "\n",
    "import operator\n",
    "sorted1 = sorted(get_fscore.items(), key=operator.itemgetter(1))\n",
    "col=sorted1\n",
    "k=[i[0] for i in col ]\n",
    "\n",
    "v=[i[1] for i in col ]\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#sns.l('features','values',dfp)\n",
    "r=range(len(k))\n",
    "plt.plot(r,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city', 'hotel5', 'type', 'source', 'bhk', 'lat', 'lon', 'price']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "sorted1 = sorted(get_fscore.items(), key=operator.itemgetter(1))\n",
    "col=sorted1\n",
    "k=[i[0] for i in col if i[1]>100]\n",
    "v=[i[1] for i in col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model3( X_train, X_test, y_train, y_test):\n",
    "   import xgboost as xgb\n",
    "   params={'colsample_bytree': 1.0,\n",
    "    'eta': .3,\n",
    "    'eval_metric': 'mae',\n",
    "    'max_depth': 4,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:linear',\n",
    "    'subsample': 0.8}\n",
    "   \n",
    "   params['eval_metric'] = \"mae\"\n",
    "   num_round = 50\n",
    "   \n",
    "   # use DMatrix for xgbosot\n",
    "   dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "   dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "   \n",
    "   watchlist = [(dtrain,'train'), (dtest,'test')]\n",
    "   \n",
    "   model = xgb.train(\n",
    "       params,\n",
    "       dtrain,\n",
    "       num_boost_round=num_round,\n",
    "       evals=watchlist,\n",
    "       early_stopping_rounds=10,\n",
    "     \n",
    "       #feval=MRE_error,\n",
    "       #obj=Linregobj\n",
    "   )\n",
    "  \n",
    "   return model.feature_names,model.get_fscore()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Split(df3):\n",
    "  \n",
    "   target=df3['rate'] \n",
    "   del df3['rate']\n",
    "   data=df3.copy()\n",
    "   from sklearn.cross_validation import train_test_split\n",
    "   X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.24, random_state=42)\n",
    "   return  X_train, X_test, y_train, y_test\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model1( X_train, X_test, y_train, y_test):\n",
    "   import xgboost as xgb\n",
    "   params={'colsample_bytree': 1.0,\n",
    "    'eta': .3,\n",
    "    'eval_metric': 'mae',\n",
    "    'max_depth': 4,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:linear',\n",
    "    'subsample': 0.8}\n",
    "   \n",
    "   params['eval_metric'] = \"mae\"\n",
    "   num_round = 7000\n",
    "   \n",
    "   # use DMatrix for xgbosot\n",
    "   dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "   dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "   \n",
    "   watchlist = [(dtrain,'train'), (dtest,'test')]\n",
    "   \n",
    "   model = xgb.train(\n",
    "       params,\n",
    "       dtrain,\n",
    "       num_boost_round=num_round,\n",
    "       evals=watchlist,\n",
    "       early_stopping_rounds=10,\n",
    "       #feval=MRE_error,\n",
    "      # obj=log_cosh_obj\n",
    "   )\n",
    "   return dtrain,params,num_round,model.feature_names,model.get_fscore(),model.get_score()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tuning(dtrain,params,num_boost_round):\n",
    "    # You can try wider intervals with a larger step between\n",
    "    # each value and then narrow it down. Here after several\n",
    "    # iteration I found that the optimal value was in the\n",
    "    # following ranges.\n",
    "    \n",
    "    gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(1,7)\n",
    "    for min_child_weight in range(1,5)\n",
    "    ]\n",
    "    \n",
    "    # Define initial best params and MAE\n",
    "    min_mae = float(\"Inf\")\n",
    "    best_params = None\n",
    "    for max_depth, min_child_weight in gridsearch_params:\n",
    "        print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "\n",
    "        # Update our parameters\n",
    "        params['max_depth'] = max_depth\n",
    "        params['min_child_weight'] = min_child_weight\n",
    "\n",
    "        # Run CV\n",
    "        cv_results = xgb.cv(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=1000,\n",
    "            seed=42,\n",
    "            nfold=5,\n",
    "            metrics={'mae'},\n",
    "            early_stopping_rounds=10\n",
    "        )\n",
    "\n",
    "        # Update best MAE\n",
    "        mean_mae = cv_results['test-mae-mean'].min()\n",
    "        boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "        print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "        if mean_mae < min_mae:\n",
    "           min_mae = mean_mae\n",
    "           best_params = (max_depth,min_child_weight)\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model2( X_train, X_test, y_train, y_test,max_depth,min_child_weight):\n",
    "   import xgboost as xgb\n",
    "\n",
    "   params={'colsample_bytree': 1.0,\n",
    "    'eta': .3,\n",
    "    'eval_metric': 'mae',\n",
    "\n",
    "    'objective': 'reg:linear',\n",
    "    'subsample': 0.8}\n",
    "   \n",
    "   params['eval_metric'] = \"mae\"\n",
    "   params['max_depth']=max_depth,\n",
    "   params['min_child_weight']=min_child_weight,\n",
    "   num_round = 4000\n",
    "   \n",
    "   # use DMatrix for xgbosot\n",
    "   dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "   dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "   \n",
    "   watchlist = [(dtrain,'train'), (dtest,'eval')]\n",
    "   \n",
    "   model = xgb.train(\n",
    "       params,\n",
    "       dtrain,\n",
    "       num_boost_round=num_round,\n",
    "       evals=watchlist,\n",
    "       early_stopping_rounds=10,\n",
    "       #feval=MRE_error,\n",
    "       #obj=Linregobj\n",
    "   )\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_approx_obj(preds, dtrain):\n",
    "    d = dtrain.get_label() - preds  #remove .get_labels() for sklearn\n",
    "    h = 1  #h is delta in the graphic\n",
    "    scale = 1 + (d / h) ** 2\n",
    "    scale_sqrt = np.sqrt(scale)\n",
    "    grad = d / scale_sqrt\n",
    "    hess = 1 / scale / scale_sqrt\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Customloss(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    grad = np.log(preds) - np.log(labels)\n",
    "    grad2 =(1-.2 *grad)*grad\n",
    "    return  grad,grad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_cosh_obj(preds, dtrain):\n",
    "    x = dtrain.get_label() - preds\n",
    "    grad = np.tanh(x)*2\n",
    "    hess = 1 / np.cosh(x)**2\n",
    "    \n",
    "    _threshold=np.median(x)\n",
    "    var =.1\n",
    "    grad = (np.abs(x)<_threshold )*grad - (np.abs(x)>=_threshold )*var\n",
    "    \n",
    "    hess = (np.abs(x)<_threshold )*hess + (np.abs(x)>=_threshold )\n",
    "    print(x)\n",
    "    return grad, hess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linregobj( preds, dtrain):\n",
    "    \n",
    "    labels = dtrain.get_label()\n",
    "    x = preds - labels\n",
    "    grad=x\n",
    "    hess = preds * (1.0-preds)\n",
    "    \n",
    "    _len=len(preds)\n",
    "    \n",
    "    _threshold=np.mean(x)\n",
    "    var =.01\n",
    "    grad = (np.abs(x)<_threshold )*grad - (np.abs(x)>=_threshold )*var\n",
    "    \n",
    "    hess = (np.abs(x)<_threshold )*hess + (np.abs(x)>=_threshold )\n",
    "    print(x)\n",
    "    return grad, hess\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MRE_error(y, y0):\n",
    "    \n",
    "    y0=y0.get_label()    \n",
    "    \n",
    "    return 'error',np.mean(np.abs(y-y0)/y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
